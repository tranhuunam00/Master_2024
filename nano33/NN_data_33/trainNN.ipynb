{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6a1b1cf0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "# import joblib\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from trainmodeltiny_createdata import create_training_data_NN_like_micro, get_keras_model_size\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0999dae1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created 31556 windows Ã— 10 samples (interleaved format)\n",
            "Created 12749 windows Ã— 10 samples (interleaved format)\n"
          ]
        }
      ],
      "source": [
        "def NeuralNetworkModel(train, test, labelTrain, labelTest):\n",
        "    train = np.array(train, dtype=np.float32)\n",
        "    test = np.array(test, dtype=np.float32)\n",
        "    labelTrain = np.array(labelTrain, dtype=np.int32)\n",
        "    labelTest = np.array(labelTest, dtype=np.int32)\n",
        "\n",
        "    if labelTrain.min() == 1:\n",
        "        labelTrain -= 1\n",
        "        labelTest -= 1\n",
        "\n",
        "    num_classes = int(max(labelTrain.max(), labelTest.max()) + 1)\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        keras.Input(shape=(train.shape[1],)),\n",
        "        layers.Dense(8, activation='relu'),\n",
        "        layers.Dense(8, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train, labelTrain, epochs=30, verbose=1, batch_size=16)\n",
        "\n",
        "    # ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p test\n",
        "    loss, accuracy = model.evaluate(test, labelTest)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "    # Dá»± Ä‘oÃ¡n trÃªn táº­p test\n",
        "    y_pred = np.argmax(model.predict(test), axis=1)\n",
        "\n",
        "    # TÃ­nh toÃ¡n ma tráº­n nháº§m láº«n\n",
        "    cm = confusion_matrix(labelTest, y_pred)\n",
        "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "    # In bÃ¡o cÃ¡o phÃ¢n loáº¡i\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(labelTest, y_pred))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "data = pd.read_csv('./input_nano_33/train_div10.csv')\n",
        "data_test = pd.read_csv('./input_nano_33/test_div10.csv')\n",
        "\n",
        "\n",
        "total_list_NN, train_labels_NN = create_training_data_NN_like_micro(data=data)\n",
        "total_list_NN_test, train_labels_NN_test = create_training_data_NN_like_micro(\n",
        "    data=data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f48152e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0180\n",
            "Epoch 2/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0070\n",
            "Epoch 3/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0063\n",
            "Epoch 4/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0032\n",
            "Epoch 5/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0062\n",
            "Epoch 6/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0026\n",
            "Epoch 7/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0022\n",
            "Epoch 8/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0017\n",
            "Epoch 9/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0032\n",
            "Epoch 10/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0028\n",
            "Epoch 11/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0032\n",
            "Epoch 12/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0010    \n",
            "Epoch 13/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0020\n",
            "Epoch 14/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 7.3206e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 5.4390e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0043\n",
            "Epoch 17/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0021\n",
            "Epoch 18/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0011    \n",
            "Epoch 19/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 8.5604e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 4.6806e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 8.2616e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0050\n",
            "Epoch 23/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 9.3193e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0027\n",
            "Epoch 25/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0016\n",
            "Epoch 26/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 7.1401e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 3.5847e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0029\n",
            "Epoch 29/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 3.0425e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m1973/1973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0028    \n",
            "\u001b[1m399/399\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8973 - loss: 1.1455\n",
            "Accuracy: 0.8973252773284912\n",
            "\u001b[1m399/399\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            " [[4950  215  606    4]\n",
            " [   0 1618    0    0]\n",
            " [   0    0 4870    0]\n",
            " [   0    0  484    2]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.86      0.92      5775\n",
            "           1       0.88      1.00      0.94      1618\n",
            "           2       0.82      1.00      0.90      4870\n",
            "           3       0.33      0.00      0.01       486\n",
            "\n",
            "    accuracy                           0.90     12749\n",
            "   macro avg       0.76      0.72      0.69     12749\n",
            "weighted avg       0.89      0.90      0.88     12749\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nnM = NeuralNetworkModel(train=total_list_NN, test=total_list_NN_test,\n",
        "                         labelTrain=train_labels_NN, labelTest=train_labels_NN_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5a960b55",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¦ NeuralNetwork: Model Size = 31.94 KB\n",
            "ğŸ”¢ Tá»•ng sá»‘ tham sá»‘ huáº¥n luyá»‡n: 356\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(31.9375, 356)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_keras_model_size(nnM, \"NeuralNetwork\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7e37b796",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 1. Kiá»ƒm tra mÃ´ hÃ¬nh Keras gá»‘c (nnM) ---\n",
            "Kiá»ƒu dá»¯ liá»‡u cá»§a Ma tráº­n Trá»ng sá»‘ Lá»›p 1 (W): float32\n",
            "KÃ­ch thÆ°á»›c (Shape) cá»§a W: (8, 8)\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Láº¥y trá»ng sá»‘ cá»§a lá»›p Dense Ä‘áº§u tiÃªn (index 1 trong model.layers)\n",
        "keras_weights = nnM.layers[1].get_weights() \n",
        "# keras_weights[0] lÃ  ma tráº­n trá»ng sá»‘, keras_weights[1] lÃ  bias\n",
        "print(\"--- 1. Kiá»ƒm tra mÃ´ hÃ¬nh Keras gá»‘c (nnM) ---\")\n",
        "print(f\"Kiá»ƒu dá»¯ liá»‡u cá»§a Ma tráº­n Trá»ng sá»‘ Lá»›p 1 (W): {keras_weights[0].dtype}\")\n",
        "print(f\"KÃ­ch thÆ°á»›c (Shape) cá»§a W: {keras_weights[0].shape}\")\n",
        "print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3d0626f6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmprz8yam5n\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmprz8yam5n\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at 'C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmprz8yam5n'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 30), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  2868686367504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686368656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686368272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686369040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686368848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686369424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Model is 3508 bytes\n"
          ]
        }
      ],
      "source": [
        "# joblib.dump(nnM, 'namth.dat')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(nnM)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"position.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "basic_model_size = os.path.getsize(\"position.tflite\")\n",
        "print(\"Model is %d bytes\" % basic_model_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bcd9eb3b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Converting baseline (no quantization) ---\n",
            "INFO:tensorflow:Assets written to: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmp_2kgv9zh\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmp_2kgv9zh\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at 'C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmp_2kgv9zh'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 30), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  2868686367504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686368656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686368272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686369040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686368848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686369424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Saved tflite_models\\model_baseline.tflite- 3508 bytes (3.43 KB)\n",
            "\n",
            "--- Converting dynamic range quantization ---\n",
            "INFO:tensorflow:Assets written to: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmpn0kffr5e\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmpn0kffr5e\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at 'C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmpn0kffr5e'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 30), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  2868686367504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686368656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686368272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686369040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686368848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686369424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Saved tflite_models\\model_dynamic_range.tflite- 3508 bytes (3.43 KB)\n",
            "\n",
            "--- Converting float16 quantization ---\n",
            "INFO:tensorflow:Assets written to: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmp6c4acryy\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmp6c4acryy\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at 'C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmp6c4acryy'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 30), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  2868686367504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686368656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686368272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686369040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686368848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686369424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Saved tflite_models\\model_float16.tflite- 3572 bytes (3.49 KB)\n",
            "\n",
            "--- Converting full integer quantization (int8) ---\n",
            "INFO:tensorflow:Assets written to: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmp52h2qcdl\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmp52h2qcdl\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at 'C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmp52h2qcdl'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 30), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  2868686367504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686368656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686368272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686369040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686368848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2868686369424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved tflite_models\\model_int8.tflite- 3272 bytes (3.20 KB)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def save_tflite(model, converter, out_path):\n",
        "    tflite_model = converter.convert()\n",
        "    open(out_path, \"wb\").write(tflite_model)\n",
        "    size_b = os.path.getsize(out_path)\n",
        "    print(f\"Saved {out_path}- {size_b} bytes ({size_b/1024:.2f} KB)\")\n",
        "    return out_path, size_b\n",
        "\n",
        "def representative_data_gen_from_array(arr, num_samples=100):\n",
        "    \"\"\"\n",
        "    arr: numpy array of shape (N, input_dim), dtype float32 (or will be cast)\n",
        "    Yields samples in the required form for TFLite representative dataset:\n",
        "        a generator that yields [input_sample.astype(np.float32)]\n",
        "    \"\"\"\n",
        "    # Shuffle to get varied samples\n",
        "    idx = np.arange(len(arr))\n",
        "    np.random.shuffle(idx)\n",
        "    idx = idx[:num_samples]\n",
        "    for i in idx:\n",
        "        sample = arr[i]\n",
        "        # ensure shape (1, input_dim)\n",
        "        sample = np.asarray(sample, dtype=np.float32).reshape(1, -1)\n",
        "        yield [sample]\n",
        "\n",
        "def convert_with_quantizations(keras_model,\n",
        "                               representative_array=None,\n",
        "                               out_dir=\"tflite_models\",\n",
        "                               rep_samples=200):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    # 1) Baseline (no quantization) - default converter\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
        "    converter.optimizations = []  # no quant\n",
        "    print(\"\\n--- Converting baseline (no quantization) ---\")\n",
        "    save_tflite(keras_model, converter, os.path.join(out_dir, \"model_baseline.tflite\"))\n",
        "\n",
        "    # 2) Dynamic range quantization (weights quantized to int8, activations float)\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    # no representative dataset needed\n",
        "    print(\"\\n--- Converting dynamic range quantization ---\")\n",
        "    save_tflite(keras_model, converter, os.path.join(out_dir, \"model_dynamic_range.tflite\"))\n",
        "\n",
        "    # 3) Float16 quantization (weights to float16) - good for CPUs that support fp16\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.target_spec.supported_types = [tf.float16]\n",
        "    print(\"\\n--- Converting float16 quantization ---\")\n",
        "    save_tflite(keras_model, converter, os.path.join(out_dir, \"model_float16.tflite\"))\n",
        "\n",
        "    # 4) Full integer quantization (weights + activations int8)- requires representative dataset\n",
        "    if representative_array is None:\n",
        "        print(\"\\n--- Skipping full integer quantization (no representative dataset provided) ---\")\n",
        "    else:\n",
        "        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
        "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "        # supported_ops ensures int8 kernels are used\n",
        "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "        # Set input and output types to int8 (or uint8)\n",
        "        converter.inference_input_type = tf.int8\n",
        "        converter.inference_output_type = tf.int8\n",
        "        # Representative dataset generator\n",
        "        gen = lambda: representative_data_gen_from_array(representative_array, num_samples=rep_samples)\n",
        "        converter.representative_dataset = gen\n",
        "\n",
        "        print(\"\\n--- Converting full integer quantization (int8) ---\")\n",
        "        try:\n",
        "            save_tflite(keras_model, converter, os.path.join(out_dir, \"model_int8.tflite\"))\n",
        "        except Exception as e:\n",
        "            print(\"Full integer conversion failed:\", e)\n",
        "            print(\"Possible reasons: some ops are not quantizable, or representative data shape/dtype mismatch.\")\n",
        "\n",
        "convert_with_quantizations(nnM, representative_array=total_list_NN, out_dir=\"tflite_models\", rep_samples=300)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
